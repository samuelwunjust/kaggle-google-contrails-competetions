{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../input/pretrained-models-pytorch\")\n",
    "sys.path.append(\"../input/efficientnet-pytorch\")\n",
    "sys.path.append(\"/kaggle/input/smp-github/segmentation_models.pytorch-master\")\n",
    "sys.path.append(\"/kaggle/input/timm-pretrained-resnest/resnest/\")\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p /root/.cache/torch/hub/checkpoints/\n",
    "!cp /kaggle/input/timm-pretrained-resnest/resnest/gluon_resnest26-50eb607c.pth /root/.cache/torch/hub/checkpoints/gluon_resnest26-50eb607c.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile config.yaml\n",
    "\n",
    "data_path: \"/kaggle/input/contrails-images-ash-color\"  # 数据路径\n",
    "output_dir: \"models\"  # 输出路径，模型保存的位置\n",
    "\n",
    "seed: 420  # 随机种子，用于确保实验可复现\n",
    "\n",
    "train_bs: 48  # 训练时的批处理大小\n",
    "valid_bs: 128  # 验证时的批处理大小\n",
    "workers: 2  # 工作线程的数量\n",
    "\n",
    "progress_bar_refresh_rate: 1  # 进度条刷新速率\n",
    "\n",
    "early_stop:  # 提前停止的设置\n",
    "    monitor: \"val_dice\"  # 监控验证损失\n",
    "    mode: \"max\"  # 当验证损失不再下降时停止\n",
    "    patience: 3  # 能够容忍多少个epoch内没有改进\n",
    "    verbose: 1  # 是否打印详细信息\n",
    "\n",
    "trainer:  # 训练器配置\n",
    "    max_epochs: 33  # 最大训练周期\n",
    "    min_epochs: 29  # 最小训练周期\n",
    "    enable_progress_bar: True  # 是否启用进度条\n",
    "    precision: \"16-mixed\"  # 训练精度\n",
    "    devices: 2  # 设备数量\n",
    "\n",
    "model:  # 模型配置\n",
    "    seg_model: \"DeepLabV3+\"  # 使用的分割模型\n",
    "    encoder_name: \"timm-efficientnet-b1\"  # 使用的编码器名称\n",
    "    loss_smooth: 1.0  # 损失平滑因子\n",
    "    image_size: 384  # 图片尺寸\n",
    "    optimizer_params:  # 优化器参数\n",
    "        lr: 0.0001  # 学习率\n",
    "        weight_decay: 0.03  # 权重衰减\n",
    "    scheduler:  # 学习率调度器配置\n",
    "        name: \"CosineAnnealingLR\"  # 调度器名称\n",
    "        params:  # 调度器参数\n",
    "            CosineAnnealingLR:  # 余弦退火学习率调度器\n",
    "                T_max: 2  # 余弦退火周期\n",
    "                eta_min: 1.0e-6  # 学习率的最小值\n",
    "                last_epoch: -1  # 最后一个epoch的索引，-1表示从头开始\n",
    "            ReduceLROnPlateau:  # 当验证损失不再下降时减小学习率\n",
    "                mode: \"min\"  # 模式选择为\"min\"\n",
    "                factor: 0.31622776602  # 学习率减少的因数\n",
    "                patience: 4  # 容忍的epoch数量\n",
    "                verbose: True  # 是否打印详细信息\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "class google_contrail_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,df,img_size=256,train=True):\n",
    "        self.df=df\n",
    "        \n",
    "        self.normalize_img=T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)) \n",
    "        self.trn=self.train\n",
    "        self.img_size=img_size\n",
    "        if self.img_size!=256:\n",
    "            self.resize_img=T.transforms.Resize(img_size)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        #obtain the row message\n",
    "        row=self.df.iloc[idx]\n",
    "        con_path=row.path\n",
    "        con=np.load(str(con_path))\n",
    "\n",
    "        #get the image and label\n",
    "        img=con[...,:-1]\n",
    "        label=con[...,-1]\n",
    "\n",
    "        #to tensor\n",
    "        label=torch.tensor(label)\n",
    "        img=torch.tensor(np.reshape(img,(256,256,3))).to(torch.float32).permute(2,0,1)\n",
    "\n",
    "        #resize\n",
    "        if self.img_size!=256:\n",
    "            img=self.resize_img(img)\n",
    "        img=self.normalize_img(img)\n",
    "\n",
    "        return img.float(),label.float()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import segmentation_models_pytorch as smp\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
    "from torch.optim import AdamW\n",
    "import torch.nn as nn\n",
    "from torchmetrics.functional import dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_models = {\n",
    "    \"Unet\": smp.Unet,\n",
    "    \"Unet++\": smp.UnetPlusPlus,\n",
    "    \"MAnet\": smp.MAnet,\n",
    "    \"Linknet\": smp.Linknet,\n",
    "    \"FPN\": smp.FPN,\n",
    "    \"PSPNet\": smp.PSPNet,\n",
    "    \"PAN\": smp.PAN,\n",
    "    \"DeepLabV3\": smp.DeepLabV3,\n",
    "    \"DeepLabV3+\": smp.DeepLabV3Plus,\n",
    "}\n",
    "class pytorch_lightning_model(pl.LightningModule):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        self.config=config\n",
    "        self.model=model=seg_models[config[\"seg_model\"]](\n",
    "        encoder_name=config[\"encoder_name\"],\n",
    "        encoder_weight=\"imagenet\",\n",
    "        in_channels=3,\n",
    "        classes=1,\n",
    "        activation=None\n",
    "\n",
    "        )\n",
    "        self.loss_module= smp.losses.DiceLoss(mode=\"binary\", smooth=config[\"loss_smooth\"]) \n",
    "        self.val_step_outputs=[]\n",
    "        self.val_step_labels=[]\n",
    "    \n",
    "    def forward(self,batch):\n",
    "        imgs=batch\n",
    "        preds=self.model(imgs)\n",
    "        return preds\n",
    "    def configure_optimizer(self):\n",
    "        optimizer=AdamW(self.parameters(),**self.config[\"optimizer_params\"])\n",
    "        if self.config[\"scheduler\"][\"name\"]==\"CosineAnnealingLR\":\n",
    "            scheduler=CosineAnnealingLR(\n",
    "                optimizer, **self.config[\"scheduler\"][\"params\"][\"CosineAnnealingLR\"],\n",
    "            )\n",
    "            lr_schduler_dict={\"scheduler\":scheduler,\"interval\":\"step\"}\n",
    "            return {\"scheduler\":scheduler,\"lr_scheduler\":lr_schduler_dict}\n",
    "        elif  self.config[\"scheduler\"][\"name\"] == \"ReduceLROnPlateau\": \n",
    "            scheduler = ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                **self.config[\"scheduler\"][\"params\"][\"ReduceLROnPlateau\"],\n",
    "            )  # define scheduler\n",
    "            lr_scheduler = {\"scheduler\": scheduler, \"monitor\": \"val_loss\"}  #mentor\n",
    "            return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler}  # return optimizer,lr_scheduler\n",
    "    def train_step(self,batch,batch_idx):\n",
    "        imgs,labels=batch\n",
    "        preds=self.model(imgs)\n",
    "        if self.config[\"img_size\"]!=256:\n",
    "            preds=torch.nn.functional.interpolate(preds,size=256,mode=\"bilinear\")\n",
    "        loss=self.loss_module(preds,labels)\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, batch_size=16)\n",
    "\n",
    "        for param_group in self.trainer.optimizers[0].param_groups:  \n",
    "            lr = param_group[\"lr\"]\n",
    "        self.log(\"lr\", lr, on_step=True, on_epoch=False, prog_bar=True)  \n",
    "\n",
    "        return loss  \n",
    "    \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        imgs,labels=batch\n",
    "        preds=self.model(imgs)\n",
    "        if self.config[\"image_size\"]!=256:\n",
    "            preds=torch.nn.functional.interpolate(preds,size=256,mode=\"bilinear\")\n",
    "        loss=self.loss_module(preds,labels)\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n",
    "        self.val_step_outputs.append(preds)\n",
    "        self.val_step_labels.append(labels)\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        all_preds=torch.cat(self.val_step_outputs)\n",
    "        all_labels=torch.cat(self.val_step_labels)\n",
    "        all_preds=torch.sigmoid(all_preds)\n",
    "        self.val_step_labels.clear()\n",
    "        self.val_step_outputs.clear()\n",
    "        val_dice=dice(all_preds,all_labels.long())\n",
    "        self.log(\"val_dice\", val_dice, on_step=False, on_epoch=True, prog_bar=True) \n",
    "        if self.trainer.global_rank == 0:  \n",
    "            print(f\"\\nEpoch: {self.current_epoch}\", flush=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")  # 忽略警告信息\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "from pprint import pprint\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, TQDMProgressBar\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "with open(\"config.yaml\",\"r\") as file:\n",
    "    config=yaml.safe_load(file)\n",
    "\n",
    "contrails=os.path.join(config[\"data_path\"],\"contrails/\")\n",
    "train_path=os.path.join(config[\"data_path\"],\"train_df.csv\")\n",
    "val_path=os.path.join(config[\"data_path\"],\"valid_df.csv\")\n",
    "\n",
    "train_df=pd.read_csv(train_path)\n",
    "valid_df=pd.read_csv(val_path)\n",
    "\n",
    "train_df[\"path\"] = contrails + train_df[\"record_id\"].astype(str) + \".npy\"\n",
    "valid_df[\"path\"] = contrails + valid_df[\"record_id\"].astype(str) + \".npy\"\n",
    "\n",
    "dataset_train=google_contrail_dataset(train_df,img_size=256,train=True)\n",
    "dataset_valid=google_contrail_dataset(valid_df,img_size=256,train=False)\n",
    "\n",
    "train_dataloader=DataLoader(\n",
    "    dataset_train,batch_size=config[\"train_bs\"],shuffle=True,num_workers=config[\"workers\"]\n",
    "\n",
    ")\n",
    "valid_dataloader=DataLoader(dataset_valid,batch_size=config[\"valid_bs\"],shuffle=False,num_workers=config['workers'])\n",
    "\n",
    "#模型保存条件\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    save_weights_only=True,\n",
    "    monitor=\"val_dice\",\n",
    "    dirpath=config[\"output_dir\"],\n",
    "    mode=\"max\",\n",
    "    filename=\"model\",\n",
    "    save_top_k=1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "progress_bar_callback = TQDMProgressBar(\n",
    "    refresh_rate=config[\"progress_bar_refresh_rate\"]\n",
    ")\n",
    "\n",
    "\n",
    "early_stop_callback = EarlyStopping(**config[\"early_stop\"])\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    callbacks=[checkpoint_callback, early_stop_callback, progress_bar_callback],\n",
    "    **config[\"trainer\"],\n",
    ")\n",
    "\n",
    "config[\"model\"][\"scheduler\"][\"params\"][\"CosineAnnealingLR\"][\"T_max\"] *= len(train_dataloader)/config[\"trainer\"][\"devices\"]\n",
    "\n",
    "# 创建模型\n",
    "model = pytorch_lightning_model(config[\"model\"])\n",
    "\n",
    "# 训练模型\n",
    "trainer.fit(model, train_dataloader, valid_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128  # 设置批处理大小\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # 判断是否有CUDA支持，如果有则使用GPU，否则使用CPU\n",
    "data = '/kaggle/input/google-research-identify-contrails-reduce-global-warming'  # 数据的总路径\n",
    "data_root = '/kaggle/input/google-research-identify-contrails-reduce-global-warming/test/'  # 测试数据的路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir(data_root)  # 获取data_root目录下的所有文件名\n",
    "test_df = pd.DataFrame(filenames, columns=['record_id'])  # 创建一个新的DataFrame，其中包含了所有文件名，作为'record_id'列\n",
    "test_df['path'] = data_root + test_df['record_id'].astype(str)  # 在DataFrame中添加新的列'path'，其中包含了每个文件的完整路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class google_contrail_dataset_test(torch.utils.data.Dataset):\n",
    "  def __init__(self,df,img_size=256,train=True):\n",
    "     self.df=df\n",
    "     self.trn=train\n",
    "     self.df_idx=pd.DataFrame({\"idx\":os.listdir(\"/kaggle/input/google-research-identify-contrails-reduce-global-warming/test\")})\n",
    "     self.normalize=T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "     self.image_size=img_size\n",
    "     if self.image_size!=256:\n",
    "        self.resize_image=T.transforms.Resize(img_size)\n",
    "  \n",
    "  def read_record(self,directory):\n",
    "     read_data={}\n",
    "     for x in [\n",
    "        \"band_11\",\n",
    "        \"band_14\",\n",
    "        \"band_15\"\n",
    "     ]:\n",
    "        read_data[x]=np.load(os.path.join(directory,x+\".npy\"))\n",
    "     return read_data\n",
    "  def normalize_range(self, data, bounds):\n",
    "    \n",
    "        return (data - bounds[0]) / (bounds[1] - bounds[0])\n",
    "    \n",
    "  def get_false_color(self, record_data):\n",
    "     \n",
    "        _T11_BOUNDS = (243, 303)\n",
    "        _CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)\n",
    "        _TDIFF_BOUNDS = (-4, 2)\n",
    "        \n",
    "        N_TIMES_BEFORE = 4\n",
    "\n",
    "        r = self.normalize_range(record_data[\"band_15\"] - record_data[\"band_14\"], _TDIFF_BOUNDS)\n",
    "        g = self.normalize_range(record_data[\"band_14\"] - record_data[\"band_11\"], _CLOUD_TOP_TDIFF_BOUNDS)\n",
    "        b = self.normalize_range(record_data[\"band_14\"], _T11_BOUNDS)\n",
    "        false_color = np.clip(np.stack([r, g, b], axis=2), 0, 1)  \n",
    "        img = false_color[..., N_TIMES_BEFORE] \n",
    "\n",
    "        return img\n",
    "  def __getitem__(self,idx):\n",
    "      row=self.df.iloc[idx]\n",
    "      con_path=row.path\n",
    "      data=self.read_record(con_path)\n",
    "      img=self.get_false_color(con_path)\n",
    "      img=torch.tensor(np.reshape(img,(256,256,3))).to(torch.float32).permute(2,0,1)\n",
    "\n",
    "      if self.image_size!=256:\n",
    "          img=self.resize_image(img)\n",
    "      image_id=int(self.df_idx.iloc[idx]['idx'])\n",
    "\n",
    "      return img.float(),torch.tensor(image_id)\n",
    "  def __len__(self):\n",
    "      return len(self.df)\n",
    "  \n",
    "\n",
    "    \n",
    "        \n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset=google_contrail_dataset(\n",
    "    test_df,config[\"model\"][\"image_size\"],False\n",
    ")\n",
    "test_dataloader=DataLoader(test_dataset,batch_size=batch_size,num_workers=1)\n",
    "\n",
    "class LightningModule(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "      \n",
    "        self.model = smp.UnetPlusPlus(encoder_name=\"timm-resnest26d\",\n",
    "                              encoder_weights=None,\n",
    "                              in_channels=3,\n",
    "                              classes=1,\n",
    "                              activation=None,\n",
    "                              )\n",
    "\n",
    "  \n",
    "    def forward(self, batch):\n",
    "        return self.model(batch)\n",
    "\n",
    "\n",
    "model = LightningModule().load_from_checkpoint(\"/kaggle/working/models/model.ckpt\")\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "model.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rle_encode(x, fg_val=1):\n",
    "    \"\"\"\n",
    "    参数:\n",
    "        x: 形状为 (height, width) 的 numpy 数组，1 表示掩膜，0 表示背景\n",
    "    返回值: 以列表形式的 run-length 编码\n",
    "    \"\"\"\n",
    "\n",
    "    dots = np.where(\n",
    "        x.T.flatten() == fg_val)[0]  # .T 将数组以列优先顺序（Fortran顺序）变平\n",
    "    run_lengths = []\n",
    "    prev = -2\n",
    "    for b in dots:\n",
    "        if b > prev + 1:\n",
    "            run_lengths.extend((b + 1, 0))\n",
    "        run_lengths[-1] += 1\n",
    "        prev = b\n",
    "    return run_lengths\n",
    "\n",
    "def list_to_string(x):\n",
    "    \"\"\"\n",
    "    将列表转换为字符串表示形式\n",
    "    空列表返回 '-'\n",
    "    \"\"\"\n",
    "    if x:  # 非空列表\n",
    "        s = str(x).replace(\"[\", \"\").replace(\"]\", \"\").replace(\",\", \"\")\n",
    "    else:\n",
    "        s = '-'\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('/kaggle/input/google-research-identify-contrails-reduce-global-warming/sample_submission.csv', index_col='record_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i ,data in enumerate(test_dataloader):\n",
    "    images,image_id=data\n",
    "    images=images.to(device)\n",
    "    with torch.no_grad():\n",
    "        pred=model.forward(images[:,:,:,:])\n",
    "    if config[\"model\"][\"image_size\"]!=256:\n",
    "        predicted_mask=torch.nn.functional.interpolate(pred,size=256,mode=\"bilinear\")\n",
    "    predicted_mask=torch.sigmoid(predicted_mask).cpu().detach().numpy()\n",
    "\n",
    "    predicted_mask_with_threshold = np.zeros((images.shape[0], 256, 256))\n",
    "    predicted_mask_with_threshold[predicted_mask[:, 0, :, :] < 0.5] = 0\n",
    "    predicted_mask_with_threshold[predicted_mask[:, 0, :, :] > 0.5] = 1\n",
    "\n",
    "    for img_num in range(0, images.shape[0]):\n",
    "        current_mask = predicted_mask_with_threshold[img_num, :, :]\n",
    "        current_image_id = image_id[img_num].item()  \n",
    "        \n",
    "       \n",
    "        submission.loc[int(current_image_id), 'encoded_pixels'] = list_to_string(rle_encode(current_mask))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
