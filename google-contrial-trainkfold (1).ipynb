{"cells":[{"cell_type":"code","execution_count":22,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-07-29T13:08:47.360841Z","iopub.status.busy":"2023-07-29T13:08:47.360331Z","iopub.status.idle":"2023-07-29T13:08:47.366793Z","shell.execute_reply":"2023-07-29T13:08:47.365670Z","shell.execute_reply.started":"2023-07-29T13:08:47.360794Z"},"trusted":true},"outputs":[],"source":["import sys\n","sys.path.append(\"../input/pretrained-models-pytorch\")\n","sys.path.append(\"../input/efficientnet-pytorch\")\n","sys.path.append(\"/kaggle/input/smp-github/segmentation_models.pytorch-master\")\n","sys.path.append(\"/kaggle/input/timm-pretrained-resnest/resnest/\")\n","import segmentation_models_pytorch as smp"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T13:08:47.369077Z","iopub.status.busy":"2023-07-29T13:08:47.368622Z","iopub.status.idle":"2023-07-29T13:08:49.555565Z","shell.execute_reply":"2023-07-29T13:08:49.554200Z","shell.execute_reply.started":"2023-07-29T13:08:47.369039Z"},"trusted":true},"outputs":[],"source":["!mkdir -p /root/.cache/torch/hub/checkpoints/\n","!cp /kaggle/input/timm-pretrained-resnest/resnest/gluon_resnest26-50eb607c.pth /root/.cache/torch/hub/checkpoints/gluon_resnest26-50eb607c.pth"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T13:08:49.558706Z","iopub.status.busy":"2023-07-29T13:08:49.558318Z","iopub.status.idle":"2023-07-29T13:08:49.568858Z","shell.execute_reply":"2023-07-29T13:08:49.567762Z","shell.execute_reply.started":"2023-07-29T13:08:49.558663Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Overwriting config.yaml\n"]}],"source":["%%writefile config.yaml\n","\n","data_path: \"/kaggle/input/contrails-images-ash-color\"\n","output_dir: \"models\"\n","\n","seed: 42\n","\n","train_bs: 48\n","valid_bs: 128\n","workers: 2\n","\n","progress_bar_refresh_rate: 1\n","\n","early_stop:\n","    monitor: \"val_loss\"\n","    mode: \"min\"\n","    patience: 999\n","    verbose: 1\n","\n","trainer:\n","    max_epochs: 26\n","    min_epochs: 26\n","    enable_progress_bar: True\n","    precision: \"16-mixed\"\n","    devices: 2\n","\n","model:\n","    seg_model: \"DeepLabV3+\"\n","    encoder_name: \"timm-resnest26d\"\n","    loss_smooth: 1.0\n","    image_size: 384\n","    optimizer_params:\n","        lr: 0.0005\n","        weight_decay: 0.0\n","    scheduler:\n","        name: \"CosineAnnealingLR\"\n","        params:\n","            CosineAnnealingLR:\n","                T_max: 2\n","                eta_min: 1.0e-6\n","                last_epoch: -1\n","            ReduceLROnPlateau:\n","                mode: \"min\"\n","                factor: 0.31622776601\n","                patience: 4\n","                verbose: True"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T13:08:49.571187Z","iopub.status.busy":"2023-07-29T13:08:49.570543Z","iopub.status.idle":"2023-07-29T13:08:49.811192Z","shell.execute_reply":"2023-07-29T13:08:49.809230Z","shell.execute_reply.started":"2023-07-29T13:08:49.570918Z"},"trusted":true},"outputs":[],"source":["import torch\n","import numpy as np\n","import torchvision.transforms as T\n","import torch\n","import numpy as np\n","import torchvision.transforms as T\n","class google_contrail_dataset(torch.utils.data.Dataset):\n","    def __init__(self,df,img_size=256,train=True):\n","        self.df=df\n","        \n","        self.normalize_img=T.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)) \n","        self.trn=train\n","        self.img_size=img_size\n","        if self.img_size!=256:\n","            self.resize_img=T.transforms.Resize(img_size)\n","    \n","    def __getitem__(self,idx):\n","        #obtain the row message\n","        row=self.df.iloc[idx]\n","        con_path=row.path\n","        con=np.load(str(con_path))\n","\n","        #get the image and label\n","        img=con[...,:-1]\n","        label=con[...,-1]\n","\n","        #to tensor\n","        label=torch.tensor(label)\n","        img=torch.tensor(np.reshape(img,(256,256,3))).to(torch.float32).permute(2,0,1)\n","\n","        #resize\n","        if self.img_size!=256:\n","            img=self.resize_img(img)\n","        img=self.normalize_img(img)\n","\n","        return img.float(),label.float()\n","    \n","    def __len__(self):\n","        return len(self.df)\n"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T13:08:49.817095Z","iopub.status.busy":"2023-07-29T13:08:49.816115Z","iopub.status.idle":"2023-07-29T13:08:49.823734Z","shell.execute_reply":"2023-07-29T13:08:49.822534Z","shell.execute_reply.started":"2023-07-29T13:08:49.817054Z"},"trusted":true},"outputs":[],"source":["import torch\n","import pytorch_lightning as pl\n","import segmentation_models_pytorch as smp\n","from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n","from torch.optim import AdamW\n","import torch.nn as nn\n","from torchmetrics.functional import dice\n"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T13:08:49.826069Z","iopub.status.busy":"2023-07-29T13:08:49.825514Z","iopub.status.idle":"2023-07-29T13:08:49.847669Z","shell.execute_reply":"2023-07-29T13:08:49.846553Z","shell.execute_reply.started":"2023-07-29T13:08:49.826036Z"},"trusted":true},"outputs":[],"source":["seg_models = {\n","    \"Unet\": smp.Unet,\n","    \"Unet++\": smp.UnetPlusPlus,\n","    \"MAnet\": smp.MAnet,\n","    \"Linknet\": smp.Linknet,\n","    \"FPN\": smp.FPN,\n","    \"PSPNet\": smp.PSPNet,\n","    \"PAN\": smp.PAN,\n","    \"DeepLabV3\": smp.DeepLabV3,\n","    \"DeepLabV3+\": smp.DeepLabV3Plus,\n","}\n","class pytorch_lightning_model(pl.LightningModule):\n","    def __init__(self,config):\n","        super().__init__()\n","        self.config=config\n","        self.model=model=seg_models[config[\"seg_model\"]](\n","        encoder_name=config[\"encoder_name\"],\n","        encoder_weights=\"imagenet\",\n","        in_channels=3,\n","        classes=1,\n","        activation=None\n","\n","        )\n","        self.loss_module= smp.losses.DiceLoss(mode=\"binary\", smooth=config[\"loss_smooth\"]) \n","        self.val_step_outputs=[]\n","        self.val_step_labels=[]\n","    \n","    def forward(self,batch):\n","        imgs=batch\n","        preds=self.model(imgs)\n","        return preds\n","    def configure_optimizers(self):\n","        optimizer=AdamW(self.parameters(),**self.config[\"optimizer_params\"])\n","        if self.config[\"scheduler\"][\"name\"] == \"CosineAnnealingLR\":\n","            scheduler = CosineAnnealingLR(\n","                optimizer,\n","                **self.config[\"scheduler\"][\"params\"][\"CosineAnnealingLR\"],\n","            )\n","            lr_scheduler_dict = {\"scheduler\": scheduler, \"interval\": \"step\"}\n","            return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler_dict}\n","        elif self.config[\"scheduler\"][\"name\"] == \"ReduceLROnPlateau\":\n","            scheduler = ReduceLROnPlateau(\n","                optimizer,\n","                **self.config[\"scheduler\"][\"params\"][\"ReduceLROnPlateau\"],\n","            )\n","            lr_scheduler = {\"scheduler\": scheduler, \"monitor\": \"val_loss\"}\n","            return {\"optimizer\": optimizer, \"lr_scheduler\": lr_scheduler}\n","\n","    def training_step(self,batch,batch_idx):\n","        imgs,labels=batch\n","        preds=self.model(imgs)\n","        if self.config[\"image_size\"]!=256:\n","            preds=torch.nn.functional.interpolate(preds,size=256,mode=\"bilinear\")\n","        loss=self.loss_module(preds,labels)\n","        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, batch_size=16)\n","\n","        for param_group in self.trainer.optimizers[0].param_groups:  \n","            lr = param_group[\"lr\"]\n","        self.log(\"lr\", lr, on_step=True, on_epoch=False, prog_bar=True)  \n","\n","        return loss  \n","    \n","    def validation_step(self,batch,batch_idx):\n","        imgs,labels=batch\n","        preds=self.model(imgs)\n","        if self.config[\"image_size\"]!=256:\n","            preds=torch.nn.functional.interpolate(preds,size=256,mode=\"bilinear\")\n","        loss=self.loss_module(preds,labels)\n","        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True)\n","        self.val_step_outputs.append(preds)\n","        self.val_step_labels.append(labels)\n","    \n","    def on_validation_epoch_end(self):\n","        all_preds=torch.cat(self.val_step_outputs)\n","        all_labels=torch.cat(self.val_step_labels)\n","        all_preds=torch.sigmoid(all_preds)\n","        self.val_step_labels.clear()\n","        self.val_step_outputs.clear()\n","        val_dice=dice(all_preds,all_labels.long())\n","        self.log(\"val_dice\", val_dice, on_step=False, on_epoch=True, prog_bar=True) \n","        if self.trainer.global_rank == 0:  \n","            print(f\"\\nEpoch: {self.current_epoch}\", flush=True)\n","\n","\n"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-07-29T13:08:49.851654Z","iopub.status.busy":"2023-07-29T13:08:49.851093Z","iopub.status.idle":"2023-07-29T13:09:14.804502Z","shell.execute_reply":"2023-07-29T13:09:14.802989Z","shell.execute_reply.started":"2023-07-29T13:08:49.851626Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Fold 1\n"]},{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">79</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">76 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>)                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">77 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">78 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># 训练模型</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>79 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>trainer.fit(model, data_loader_train, data_loader_validation)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">80 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">trainer.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">531</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">fit</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 528 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 529 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>model = _maybe_unwrap_optimized(model)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 530 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.strategy._lightning_module = model                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 531 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>call._call_and_handle_interrupt(                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 532 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._fit_impl, model, train_dataloaders, val_dataloaders, datamodule,  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 533 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 534 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">call.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">41</span> in                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_call_and_handle_interrupt</span>                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 38 </span><span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">\"\"\"</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 39 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 40 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> trainer.strategy.launcher <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>:                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 41 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer,    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 42 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> trainer_fn(*args, **kwargs)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 43 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 44 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> _TunerExitException:                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">multiprocessing.p</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">y</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">124</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">launch</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">121 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>join=<span style=\"color: #0000ff; text-decoration-color: #0000ff\">False</span>,  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># we will join ourselves to get the process references</span>            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">122 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>)                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">123 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.procs = process_context.processes                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>124 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">while</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> process_context.join():                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">125 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">pass</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">126 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">127 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>worker_output = return_queue.get()                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">spawn.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">160</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">join</span>               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">157 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>original_trace = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.error_queues[error_index].get()                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">158 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>msg = <span style=\"color: #808000; text-decoration-color: #808000\">\"\\n\\n-- Process %d terminated with the following error:\\n\"</span> % error_index     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">159 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>msg += original_trace                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>160 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> ProcessRaisedException(msg, error_index, failed_process.pid)                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">161 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">162 </span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">163 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">SpawnContext</span>(ProcessContext):                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n","<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n","<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">ProcessRaisedException: </span>\n","\n","-- Process <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> terminated with the following error:\n","Traceback <span style=\"font-weight: bold\">(</span>most recent call last<span style=\"font-weight: bold\">)</span>:\n","  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">69</span>, in _wrap\n","    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">fn</span><span style=\"font-weight: bold\">(</span>i, *args<span style=\"font-weight: bold\">)</span>\n","  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py\"</span>, line \n","<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">147</span>, in _wrapping_function\n","    results = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">function</span><span style=\"font-weight: bold\">(</span>*args, **kwargs<span style=\"font-weight: bold\">)</span>\n","  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">570</span>, in _fit_impl\n","    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self._run</span><span style=\"font-weight: bold\">(</span>model, <span style=\"color: #808000; text-decoration-color: #808000\">ckpt_path</span>=<span style=\"color: #800080; text-decoration-color: #800080\">ckpt_path</span><span style=\"font-weight: bold\">)</span>\n","  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">975</span>, in _run\n","    results = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self._run_stage</span><span style=\"font-weight: bold\">()</span>\n","  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1016</span>, in _run_stage\n","    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self._run_sanity_check</span><span style=\"font-weight: bold\">()</span>\n","  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1045</span>, in \n","_run_sanity_check\n","    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">val_loop.run</span><span style=\"font-weight: bold\">()</span>\n","  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">177</span>, in _decorator\n","    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">loop_run</span><span style=\"font-weight: bold\">(</span>self, *args, **kwargs<span style=\"font-weight: bold\">)</span>\n","  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">115</span>, in run\n","    <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self._evaluation_step</span><span style=\"font-weight: bold\">(</span>batch, batch_idx, dataloader_idx<span style=\"font-weight: bold\">)</span>\n","  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">375</span>, in \n","_evaluation_step\n","    output = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">call._call_strategy_hook</span><span style=\"font-weight: bold\">(</span>trainer, hook_name, *<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">step_kwargs.values</span><span style=\"font-weight: bold\">())</span>\n","  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">287</span>, in \n","_call_strategy_hook\n","    output = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">fn</span><span style=\"font-weight: bold\">(</span>*args, **kwargs<span style=\"font-weight: bold\">)</span>\n","  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">336</span>, in validation_step\n","    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.model</span><span style=\"font-weight: bold\">(</span>*args, **kwargs<span style=\"font-weight: bold\">)</span>\n","  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1501</span>, in _call_impl\n","    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">forward_call</span><span style=\"font-weight: bold\">(</span>*args, **kwargs<span style=\"font-weight: bold\">)</span>\n","  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1156</span>, in forward\n","    output = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self._run_ddp_forward</span><span style=\"font-weight: bold\">(</span>*inputs, **kwargs<span style=\"font-weight: bold\">)</span>\n","  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1110</span>, in _run_ddp_forward\n","    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">module_to_run</span><span style=\"font-weight: bold\">(</span>*inputs<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">]</span>, **kwargs<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">])</span>  # type: ignore<span style=\"font-weight: bold\">[</span>index<span style=\"font-weight: bold\">]</span>\n","  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1501</span>, in _call_impl\n","    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">forward_call</span><span style=\"font-weight: bold\">(</span>*args, **kwargs<span style=\"font-weight: bold\">)</span>\n","  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/overrides/base.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">102</span>, in forward\n","    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self._forward_module.validation_step</span><span style=\"font-weight: bold\">(</span>*inputs, **kwargs<span style=\"font-weight: bold\">)</span>\n","  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/tmp/ipykernel_29/1040615569.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">65</span>, in validation_step\n","    <span style=\"color: #808000; text-decoration-color: #808000\">preds</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.model</span><span style=\"font-weight: bold\">(</span>imgs<span style=\"font-weight: bold\">)</span>\n","  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1501</span>, in _call_impl\n","    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">forward_call</span><span style=\"font-weight: bold\">(</span>*args, **kwargs<span style=\"font-weight: bold\">)</span>\n","  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/kaggle/input/smp-github/segmentation_models.pytorch-master/segmentation_models_pytorch/base/model.py\"</span>, \n","line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>, in forward\n","    decoder_output = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">self.decoder</span><span style=\"font-weight: bold\">(</span>*features<span style=\"font-weight: bold\">)</span>\n","  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1501</span>, in _call_impl\n","    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">forward_call</span><span style=\"font-weight: bold\">(</span>*args, **kwargs<span style=\"font-weight: bold\">)</span>\n","  File \n","<span style=\"color: #008000; text-decoration-color: #008000\">\"/kaggle/input/smp-github/segmentation_models.pytorch-master/segmentation_models_pytorch/decoders/unetplusplus/deco</span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">der.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">135</span>, in forward\n","    dense_x<span style=\"font-weight: bold\">[</span>f\"x_<span style=\"font-weight: bold\">{</span>depth_idx<span style=\"font-weight: bold\">}</span>_<span style=\"font-weight: bold\">{</span>dense_l_i<span style=\"font-weight: bold\">}</span><span style=\"color: #008000; text-decoration-color: #008000\">\"] = self.blocks[f\"</span>x_<span style=\"font-weight: bold\">{</span>depth_idx<span style=\"font-weight: bold\">}</span>_<span style=\"font-weight: bold\">{</span>dense_l_i<span style=\"font-weight: bold\">}</span>\"<span style=\"font-weight: bold\">](</span>\n","  File <span style=\"color: #008000; text-decoration-color: #008000\">\"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1501</span>, in _call_impl\n","    return <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">forward_call</span><span style=\"font-weight: bold\">(</span>*args, **kwargs<span style=\"font-weight: bold\">)</span>\n","  File \n","<span style=\"color: #008000; text-decoration-color: #008000\">\"/kaggle/input/smp-github/segmentation_models.pytorch-master/segmentation_models_pytorch/decoders/unetplusplus/deco</span>\n","<span style=\"color: #008000; text-decoration-color: #008000\">der.py\"</span>, line <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">38</span>, in forward\n","    x = <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.cat</span><span style=\"font-weight: bold\">([</span>x, skip<span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dim</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>\n","torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.94</span> GiB <span style=\"font-weight: bold\">(</span>GPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14.76</span> GiB total capacity; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8.95</span> \n","GiB already allocated; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">459.75</span> MiB free; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13.06</span> GiB reserved in total by PyTorch<span style=\"font-weight: bold\">)</span> If reserved memory is &gt;&gt; allocated \n","memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n","PYTORCH_CUDA_ALLOC_CONF\n","\n","</pre>\n"],"text/plain":["\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n","\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m79\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m76 \u001b[0m\u001b[2m│   \u001b[0m)                                                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m77 \u001b[0m\u001b[2m│   \u001b[0m                                                                                        \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m78 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# 训练模型\u001b[0m                                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m79 \u001b[2m│   \u001b[0mtrainer.fit(model, data_loader_train, data_loader_validation)                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m80 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/\u001b[0m\u001b[1;33mtrainer.py\u001b[0m:\u001b[94m531\u001b[0m in \u001b[92mfit\u001b[0m          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 528 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 529 \u001b[0m\u001b[2m│   │   \u001b[0mmodel = _maybe_unwrap_optimized(model)                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 530 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.strategy._lightning_module = model                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 531 \u001b[2m│   │   \u001b[0mcall._call_and_handle_interrupt(                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 532 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m, \u001b[96mself\u001b[0m._fit_impl, model, train_dataloaders, val_dataloaders, datamodule,  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 533 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 534 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/\u001b[0m\u001b[1;33mcall.py\u001b[0m:\u001b[94m41\u001b[0m in                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[92m_call_and_handle_interrupt\u001b[0m                                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 38 \u001b[0m\u001b[2;33m│   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 39 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mtry\u001b[0m:                                                                                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 40 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m trainer.strategy.launcher \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m:                                          \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 41 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer,    \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 42 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m trainer_fn(*args, **kwargs)                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 43 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m 44 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mexcept\u001b[0m _TunerExitException:                                                            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/\u001b[0m\u001b[1;33mmultiprocessing.p\u001b[0m \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[1;33my\u001b[0m:\u001b[94m124\u001b[0m in \u001b[92mlaunch\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m121 \u001b[0m\u001b[2m│   │   │   \u001b[0mjoin=\u001b[94mFalse\u001b[0m,  \u001b[2m# we will join ourselves to get the process references\u001b[0m            \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m122 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m123 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.procs = process_context.processes                                             \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m124 \u001b[2m│   │   \u001b[0m\u001b[94mwhile\u001b[0m \u001b[95mnot\u001b[0m process_context.join():                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m125 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mpass\u001b[0m                                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m126 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                   \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m127 \u001b[0m\u001b[2m│   │   \u001b[0mworker_output = return_queue.get()                                                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[2;33m/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/\u001b[0m\u001b[1;33mspawn.py\u001b[0m:\u001b[94m160\u001b[0m in \u001b[92mjoin\u001b[0m               \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m157 \u001b[0m\u001b[2m│   │   \u001b[0moriginal_trace = \u001b[96mself\u001b[0m.error_queues[error_index].get()                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m158 \u001b[0m\u001b[2m│   │   \u001b[0mmsg = \u001b[33m\"\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m-- Process \u001b[0m\u001b[33m%d\u001b[0m\u001b[33m terminated with the following error:\u001b[0m\u001b[33m\\n\u001b[0m\u001b[33m\"\u001b[0m % error_index     \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m159 \u001b[0m\u001b[2m│   │   \u001b[0mmsg += original_trace                                                              \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m160 \u001b[2m│   │   \u001b[0m\u001b[94mraise\u001b[0m ProcessRaisedException(msg, error_index, failed_process.pid)                 \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m161 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m162 \u001b[0m                                                                                           \u001b[31m│\u001b[0m\n","\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92mSpawnContext\u001b[0m(ProcessContext):                                                        \u001b[31m│\u001b[0m\n","\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n","\u001b[1;91mProcessRaisedException: \u001b[0m\n","\n","-- Process \u001b[1;36m1\u001b[0m terminated with the following error:\n","Traceback \u001b[1m(\u001b[0mmost recent call last\u001b[1m)\u001b[0m:\n","  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/torch/multiprocessing/spawn.py\"\u001b[0m, line \u001b[1;36m69\u001b[0m, in _wrap\n","    \u001b[1;35mfn\u001b[0m\u001b[1m(\u001b[0mi, *args\u001b[1m)\u001b[0m\n","  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/launchers/multiprocessing.py\"\u001b[0m, line \n","\u001b[1;36m147\u001b[0m, in _wrapping_function\n","    results = \u001b[1;35mfunction\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m\n","  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\"\u001b[0m, line \u001b[1;36m570\u001b[0m, in _fit_impl\n","    \u001b[1;35mself._run\u001b[0m\u001b[1m(\u001b[0mmodel, \u001b[33mckpt_path\u001b[0m=\u001b[35mckpt_path\u001b[0m\u001b[1m)\u001b[0m\n","  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\"\u001b[0m, line \u001b[1;36m975\u001b[0m, in _run\n","    results = \u001b[1;35mself._run_stage\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n","  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\"\u001b[0m, line \u001b[1;36m1016\u001b[0m, in _run_stage\n","    \u001b[1;35mself._run_sanity_check\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n","  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py\"\u001b[0m, line \u001b[1;36m1045\u001b[0m, in \n","_run_sanity_check\n","    \u001b[1;35mval_loop.run\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\n","  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/utilities.py\"\u001b[0m, line \u001b[1;36m177\u001b[0m, in _decorator\n","    return \u001b[1;35mloop_run\u001b[0m\u001b[1m(\u001b[0mself, *args, **kwargs\u001b[1m)\u001b[0m\n","  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\"\u001b[0m, line \u001b[1;36m115\u001b[0m, in run\n","    \u001b[1;35mself._evaluation_step\u001b[0m\u001b[1m(\u001b[0mbatch, batch_idx, dataloader_idx\u001b[1m)\u001b[0m\n","  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/evaluation_loop.py\"\u001b[0m, line \u001b[1;36m375\u001b[0m, in \n","_evaluation_step\n","    output = \u001b[1;35mcall._call_strategy_hook\u001b[0m\u001b[1m(\u001b[0mtrainer, hook_name, *\u001b[1;35mstep_kwargs.values\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m\u001b[1m)\u001b[0m\n","  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py\"\u001b[0m, line \u001b[1;36m287\u001b[0m, in \n","_call_strategy_hook\n","    output = \u001b[1;35mfn\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m\n","  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/strategies/ddp.py\"\u001b[0m, line \u001b[1;36m336\u001b[0m, in validation_step\n","    return \u001b[1;35mself.model\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m\n","  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[1;36m1501\u001b[0m, in _call_impl\n","    return \u001b[1;35mforward_call\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m\n","  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\"\u001b[0m, line \u001b[1;36m1156\u001b[0m, in forward\n","    output = \u001b[1;35mself._run_ddp_forward\u001b[0m\u001b[1m(\u001b[0m*inputs, **kwargs\u001b[1m)\u001b[0m\n","  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/distributed.py\"\u001b[0m, line \u001b[1;36m1110\u001b[0m, in _run_ddp_forward\n","    return \u001b[1;35mmodule_to_run\u001b[0m\u001b[1m(\u001b[0m*inputs\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m, **kwargs\u001b[1m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m  # type: ignore\u001b[1m[\u001b[0mindex\u001b[1m]\u001b[0m\n","  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[1;36m1501\u001b[0m, in _call_impl\n","    return \u001b[1;35mforward_call\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m\n","  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/overrides/base.py\"\u001b[0m, line \u001b[1;36m102\u001b[0m, in forward\n","    return \u001b[1;35mself._forward_module.validation_step\u001b[0m\u001b[1m(\u001b[0m*inputs, **kwargs\u001b[1m)\u001b[0m\n","  File \u001b[32m\"/tmp/ipykernel_29/1040615569.py\"\u001b[0m, line \u001b[1;36m65\u001b[0m, in validation_step\n","    \u001b[33mpreds\u001b[0m=\u001b[1;35mself\u001b[0m\u001b[1;35m.model\u001b[0m\u001b[1m(\u001b[0mimgs\u001b[1m)\u001b[0m\n","  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[1;36m1501\u001b[0m, in _call_impl\n","    return \u001b[1;35mforward_call\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m\n","  File \u001b[32m\"/kaggle/input/smp-github/segmentation_models.pytorch-master/segmentation_models_pytorch/base/model.py\"\u001b[0m, \n","line \u001b[1;36m30\u001b[0m, in forward\n","    decoder_output = \u001b[1;35mself.decoder\u001b[0m\u001b[1m(\u001b[0m*features\u001b[1m)\u001b[0m\n","  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[1;36m1501\u001b[0m, in _call_impl\n","    return \u001b[1;35mforward_call\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m\n","  File \n","\u001b[32m\"/kaggle/input/smp-github/segmentation_models.pytorch-master/segmentation_models_pytorch/decoders/unetplusplus/deco\u001b[0m\n","\u001b[32mder.py\"\u001b[0m, line \u001b[1;36m135\u001b[0m, in forward\n","    dense_x\u001b[1m[\u001b[0mf\"x_\u001b[1m{\u001b[0mdepth_idx\u001b[1m}\u001b[0m_\u001b[1m{\u001b[0mdense_l_i\u001b[1m}\u001b[0m\u001b[32m\"\u001b[0m\u001b[32m]\u001b[0m\u001b[32m = self.blocks\u001b[0m\u001b[32m[\u001b[0m\u001b[32mf\"\u001b[0mx_\u001b[1m{\u001b[0mdepth_idx\u001b[1m}\u001b[0m_\u001b[1m{\u001b[0mdense_l_i\u001b[1m}\u001b[0m\"\u001b[1m]\u001b[0m\u001b[1m(\u001b[0m\n","  File \u001b[32m\"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py\"\u001b[0m, line \u001b[1;36m1501\u001b[0m, in _call_impl\n","    return \u001b[1;35mforward_call\u001b[0m\u001b[1m(\u001b[0m*args, **kwargs\u001b[1m)\u001b[0m\n","  File \n","\u001b[32m\"/kaggle/input/smp-github/segmentation_models.pytorch-master/segmentation_models_pytorch/decoders/unetplusplus/deco\u001b[0m\n","\u001b[32mder.py\"\u001b[0m, line \u001b[1;36m38\u001b[0m, in forward\n","    x = \u001b[1;35mtorch.cat\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0mx, skip\u001b[1m]\u001b[0m, \u001b[33mdim\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m\n","torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate \u001b[1;36m3.94\u001b[0m GiB \u001b[1m(\u001b[0mGPU \u001b[1;36m1\u001b[0m; \u001b[1;36m14.76\u001b[0m GiB total capacity; \u001b[1;36m8.95\u001b[0m \n","GiB already allocated; \u001b[1;36m459.75\u001b[0m MiB free; \u001b[1;36m13.06\u001b[0m GiB reserved in total by PyTorch\u001b[1m)\u001b[0m If reserved memory is >> allocated \n","memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n","PYTORCH_CUDA_ALLOC_CONF\n","\n"]},"metadata":{},"output_type":"display_data"}],"source":["import warnings\n","\n","warnings.filterwarnings(\"ignore\")  # 忽略警告信息\n","\n","import os\n","import torch\n","import yaml\n","import pandas as pd\n","import pytorch_lightning as pl\n","from pprint import pprint\n","from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping, TQDMProgressBar\n","from pytorch_lightning.callbacks.stochastic_weight_avg import StochasticWeightAveraging\n","from torch.utils.data import DataLoader\n","\n","with open(\"config.yaml\", \"r\") as file_obj:  # 打开配置文件并读取内容\n","    config = yaml.safe_load(file_obj)\n","\n","contrails = os.path.join(config[\"data_path\"], \"contrails/\")  # 设置训练数据的路径\n","train_path = os.path.join(config[\"data_path\"], \"train_df.csv\")  # 设置训练数据标签文件的路径\n","valid_path = os.path.join(config[\"data_path\"], \"valid_df.csv\")  # 设置验证数据标签文件的路径\n","\n","train_df = pd.read_csv(train_path)  # 读取训练数据标签\n","valid_df = pd.read_csv(valid_path)  # 读取验证数据标签\n","\n","\n","\n","\n","total_df = pd.concat([train_df, valid_df], ignore_index=True)\n","\n","from sklearn.model_selection import KFold\n","\n","n_splits = 5  \n","kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n","\n","# 对于每一折，我们将数据分为训练集和验证集\n","for fold, (train_indices, val_indices) in enumerate(kfold.split(total_df)):\n","    print(f\"Fold {fold + 1}\")\n","    \n","    train_fold = total_df.iloc[train_indices]\n","    valid_fold = total_df.iloc[val_indices]\n","\n","    train_fold[\"path\"] = contrails + train_fold[\"record_id\"].astype(str) + \".npy\"\n","    valid_fold[\"path\"] = contrails + valid_fold[\"record_id\"].astype(str) + \".npy\"\n","\n","    dataset_train = google_contrail_dataset(train_fold, config[\"model\"][\"image_size\"], train=True)\n","    dataset_validation = google_contrail_dataset(valid_fold, config[\"model\"][\"image_size\"], train=False)\n","\n","    data_loader_train = DataLoader(\n","        dataset_train,\n","        batch_size=config[\"train_bs\"],\n","        shuffle=True,\n","        num_workers=config[\"workers\"],\n","    )\n","    data_loader_validation = DataLoader(\n","        dataset_validation,\n","        batch_size=config[\"valid_bs\"],\n","        shuffle=False,\n","        num_workers=config[\"workers\"],\n","    )\n","\n","\n","    model = pytorch_lightning_model(config[\"model\"])\n","\n","    checkpoint_callback = ModelCheckpoint(\n","        monitor=\"val_dice\",\n","        dirpath=f\"models/fold_{fold + 1}\",  # 为每个折创建一个新的目录\n","        filename=\"best_model\",  # 保存最佳模型的文件名\n","        save_top_k=1,\n","        mode=\"max\",  # “max”表示我们希望在验证集上的Dice值最大时保存模型\n","    )\n","\n","    # 创建训练器\n","    trainer = pl.Trainer(\n","        callbacks=[checkpoint_callback],\n","        **config[\"trainer\"],\n","    )\n","\n","    # 训练模型\n","    trainer.fit(model, data_loader_train, data_loader_validation)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
